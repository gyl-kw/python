{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "==== Running Experiment: Optimizer=sgd, Scheduler=step ====\n",
      "Epoch 1/50 | Loss: 2.1241 | Acc: 22.41%\n",
      "Epoch 2/50 | Loss: 1.8484 | Acc: 31.21%\n",
      "Epoch 3/50 | Loss: 1.7943 | Acc: 33.71%\n",
      "Epoch 4/50 | Loss: 1.7483 | Acc: 35.75%\n",
      "Epoch 5/50 | Loss: 1.7231 | Acc: 37.09%\n",
      "Epoch 6/50 | Loss: 1.6961 | Acc: 38.77%\n",
      "Epoch 7/50 | Loss: 1.6935 | Acc: 39.19%\n",
      "Epoch 8/50 | Loss: 1.6973 | Acc: 39.01%\n",
      "Epoch 9/50 | Loss: 1.7055 | Acc: 39.01%\n",
      "Epoch 10/50 | Loss: 1.7007 | Acc: 38.63%\n",
      "Epoch 11/50 | Loss: 1.7005 | Acc: 39.22%\n",
      "Epoch 12/50 | Loss: 1.7065 | Acc: 38.62%\n",
      "Epoch 13/50 | Loss: 1.6904 | Acc: 39.51%\n",
      "Epoch 14/50 | Loss: 1.6964 | Acc: 39.18%\n",
      "Epoch 15/50 | Loss: 1.7104 | Acc: 38.22%\n",
      "Epoch 16/50 | Loss: 1.7108 | Acc: 38.46%\n",
      "Epoch 17/50 | Loss: 1.7424 | Acc: 37.01%\n",
      "Epoch 18/50 | Loss: 1.7222 | Acc: 37.50%\n",
      "Epoch 19/50 | Loss: 1.7597 | Acc: 36.88%\n",
      "Epoch 20/50 | Loss: 1.7527 | Acc: 37.01%\n",
      "Epoch 21/50 | Loss: 1.7537 | Acc: 36.86%\n",
      "Epoch 22/50 | Loss: 1.7710 | Acc: 35.36%\n",
      "Epoch 23/50 | Loss: 1.7756 | Acc: 35.74%\n",
      "Epoch 24/50 | Loss: 1.7738 | Acc: 36.08%\n",
      "Epoch 25/50 | Loss: 1.7722 | Acc: 36.04%\n",
      "Epoch 26/50 | Loss: 1.7774 | Acc: 35.73%\n",
      "Epoch 27/50 | Loss: 1.7596 | Acc: 36.19%\n",
      "Epoch 28/50 | Loss: 1.7553 | Acc: 36.64%\n",
      "Epoch 29/50 | Loss: 1.7707 | Acc: 35.88%\n",
      "Epoch 30/50 | Loss: 1.7672 | Acc: 36.33%\n",
      "Epoch 31/50 | Loss: 1.3240 | Acc: 52.23%\n",
      "Epoch 32/50 | Loss: 1.2282 | Acc: 56.24%\n",
      "Epoch 33/50 | Loss: 1.1830 | Acc: 58.20%\n",
      "Epoch 34/50 | Loss: 1.1512 | Acc: 59.45%\n",
      "Epoch 35/50 | Loss: 1.1295 | Acc: 60.52%\n",
      "Epoch 36/50 | Loss: 1.1062 | Acc: 61.70%\n",
      "Epoch 37/50 | Loss: 1.0789 | Acc: 62.98%\n",
      "Epoch 38/50 | Loss: 1.0565 | Acc: 63.76%\n",
      "Epoch 39/50 | Loss: 1.0405 | Acc: 64.54%\n",
      "Epoch 40/50 | Loss: 1.0307 | Acc: 64.83%\n",
      "Epoch 41/50 | Loss: 1.0185 | Acc: 65.55%\n",
      "Epoch 42/50 | Loss: 1.0094 | Acc: 66.10%\n",
      "Epoch 43/50 | Loss: 0.9902 | Acc: 66.81%\n",
      "Epoch 44/50 | Loss: 0.9818 | Acc: 67.16%\n",
      "Epoch 45/50 | Loss: 0.9771 | Acc: 67.32%\n",
      "Epoch 46/50 | Loss: 0.9660 | Acc: 67.92%\n",
      "Epoch 47/50 | Loss: 0.9568 | Acc: 68.29%\n",
      "Epoch 48/50 | Loss: 0.9500 | Acc: 68.41%\n",
      "Epoch 49/50 | Loss: 0.9493 | Acc: 68.69%\n",
      "Epoch 50/50 | Loss: 0.9488 | Acc: 68.62%\n",
      "\n",
      "==== Running Experiment: Optimizer=sgd, Scheduler=cosine ====\n",
      "Epoch 1/50 | Loss: 2.1676 | Acc: 19.91%\n",
      "Epoch 2/50 | Loss: 1.8546 | Acc: 30.86%\n",
      "Epoch 3/50 | Loss: 1.8052 | Acc: 33.52%\n",
      "Epoch 4/50 | Loss: 1.7770 | Acc: 35.10%\n",
      "Epoch 5/50 | Loss: 1.7547 | Acc: 36.33%\n",
      "Epoch 6/50 | Loss: 1.7341 | Acc: 37.01%\n",
      "Epoch 7/50 | Loss: 1.7099 | Acc: 38.47%\n",
      "Epoch 8/50 | Loss: 1.6947 | Acc: 39.30%\n",
      "Epoch 9/50 | Loss: 1.6819 | Acc: 39.98%\n",
      "Epoch 10/50 | Loss: 1.6581 | Acc: 40.68%\n",
      "Epoch 11/50 | Loss: 1.6543 | Acc: 40.98%\n",
      "Epoch 12/50 | Loss: 1.6366 | Acc: 42.04%\n",
      "Epoch 13/50 | Loss: 1.6233 | Acc: 42.76%\n",
      "Epoch 14/50 | Loss: 1.6058 | Acc: 43.03%\n",
      "Epoch 15/50 | Loss: 1.5940 | Acc: 43.71%\n",
      "Epoch 16/50 | Loss: 1.5667 | Acc: 44.76%\n",
      "Epoch 17/50 | Loss: 1.5529 | Acc: 45.47%\n",
      "Epoch 18/50 | Loss: 1.5384 | Acc: 46.32%\n",
      "Epoch 19/50 | Loss: 1.5115 | Acc: 47.45%\n",
      "Epoch 20/50 | Loss: 1.4870 | Acc: 48.36%\n",
      "Epoch 21/50 | Loss: 1.4654 | Acc: 49.04%\n",
      "Epoch 22/50 | Loss: 1.4396 | Acc: 50.24%\n",
      "Epoch 23/50 | Loss: 1.4177 | Acc: 50.73%\n",
      "Epoch 24/50 | Loss: 1.3905 | Acc: 51.86%\n",
      "Epoch 25/50 | Loss: 1.3663 | Acc: 53.28%\n",
      "Epoch 26/50 | Loss: 1.3395 | Acc: 53.94%\n",
      "Epoch 27/50 | Loss: 1.3110 | Acc: 55.23%\n",
      "Epoch 28/50 | Loss: 1.2864 | Acc: 56.05%\n",
      "Epoch 29/50 | Loss: 1.2590 | Acc: 57.24%\n",
      "Epoch 30/50 | Loss: 1.2306 | Acc: 57.94%\n",
      "Epoch 31/50 | Loss: 1.1883 | Acc: 59.82%\n",
      "Epoch 32/50 | Loss: 1.1633 | Acc: 60.76%\n",
      "Epoch 33/50 | Loss: 1.1225 | Acc: 62.02%\n",
      "Epoch 34/50 | Loss: 1.0911 | Acc: 63.14%\n",
      "Epoch 35/50 | Loss: 1.0605 | Acc: 64.57%\n",
      "Epoch 36/50 | Loss: 1.0244 | Acc: 65.78%\n",
      "Epoch 37/50 | Loss: 0.9924 | Acc: 66.78%\n",
      "Epoch 38/50 | Loss: 0.9496 | Acc: 68.24%\n",
      "Epoch 39/50 | Loss: 0.9134 | Acc: 69.50%\n",
      "Epoch 40/50 | Loss: 0.8774 | Acc: 70.48%\n",
      "Epoch 41/50 | Loss: 0.8273 | Acc: 72.32%\n",
      "Epoch 42/50 | Loss: 0.7860 | Acc: 73.40%\n",
      "Epoch 43/50 | Loss: 0.7513 | Acc: 74.81%\n",
      "Epoch 44/50 | Loss: 0.7033 | Acc: 76.33%\n",
      "Epoch 45/50 | Loss: 0.6613 | Acc: 77.66%\n",
      "Epoch 46/50 | Loss: 0.6151 | Acc: 79.15%\n",
      "Epoch 47/50 | Loss: 0.5745 | Acc: 80.67%\n",
      "Epoch 48/50 | Loss: 0.5414 | Acc: 81.66%\n",
      "Epoch 49/50 | Loss: 0.5150 | Acc: 82.63%\n",
      "Epoch 50/50 | Loss: 0.4899 | Acc: 83.46%\n",
      "\n",
      "==== Running Experiment: Optimizer=sgd, Scheduler=plateau ====\n",
      "Epoch 1/50 | Loss: 2.1940 | Acc: 18.20%\n",
      "Epoch 2/50 | Loss: 1.8876 | Acc: 28.82%\n",
      "Epoch 3/50 | Loss: 1.8142 | Acc: 32.99%\n",
      "Epoch 4/50 | Loss: 1.7574 | Acc: 35.86%\n",
      "Epoch 5/50 | Loss: 1.7239 | Acc: 37.41%\n",
      "Epoch 6/50 | Loss: 1.7174 | Acc: 37.84%\n",
      "Epoch 7/50 | Loss: 1.7105 | Acc: 38.13%\n",
      "Epoch 8/50 | Loss: 1.7000 | Acc: 38.76%\n",
      "Epoch 9/50 | Loss: 1.7006 | Acc: 38.98%\n",
      "Epoch 10/50 | Loss: 1.6981 | Acc: 39.03%\n",
      "Epoch 11/50 | Loss: 1.7082 | Acc: 38.75%\n",
      "Epoch 12/50 | Loss: 1.6954 | Acc: 39.20%\n",
      "Epoch 13/50 | Loss: 1.7047 | Acc: 38.76%\n",
      "Epoch 14/50 | Loss: 1.6986 | Acc: 39.33%\n",
      "Epoch 15/50 | Loss: 1.6883 | Acc: 39.70%\n",
      "Epoch 16/50 | Loss: 1.6951 | Acc: 39.57%\n",
      "Epoch 17/50 | Loss: 1.7008 | Acc: 38.99%\n",
      "Epoch 18/50 | Loss: 1.6994 | Acc: 39.14%\n",
      "Epoch 19/50 | Loss: 1.6943 | Acc: 39.23%\n",
      "Epoch 20/50 | Loss: 1.7057 | Acc: 38.78%\n",
      "Epoch 21/50 | Loss: 1.7101 | Acc: 38.51%\n",
      "Epoch 22/50 | Loss: 1.5157 | Acc: 46.62%\n",
      "Epoch 23/50 | Loss: 1.4722 | Acc: 48.27%\n",
      "Epoch 24/50 | Loss: 1.4579 | Acc: 49.17%\n",
      "Epoch 25/50 | Loss: 1.4264 | Acc: 50.54%\n",
      "Epoch 26/50 | Loss: 1.4228 | Acc: 50.75%\n",
      "Epoch 27/50 | Loss: 1.4204 | Acc: 50.87%\n",
      "Epoch 28/50 | Loss: 1.4052 | Acc: 51.56%\n",
      "Epoch 29/50 | Loss: 1.4058 | Acc: 51.74%\n",
      "Epoch 30/50 | Loss: 1.4080 | Acc: 51.71%\n",
      "Epoch 31/50 | Loss: 1.3949 | Acc: 51.93%\n",
      "Epoch 32/50 | Loss: 1.3863 | Acc: 52.15%\n",
      "Epoch 33/50 | Loss: 1.4168 | Acc: 51.33%\n",
      "Epoch 34/50 | Loss: 1.3963 | Acc: 52.15%\n",
      "Epoch 35/50 | Loss: 1.3986 | Acc: 51.74%\n",
      "Epoch 36/50 | Loss: 1.4019 | Acc: 51.94%\n",
      "Epoch 37/50 | Loss: 1.3879 | Acc: 52.21%\n",
      "Epoch 38/50 | Loss: 1.4067 | Acc: 51.87%\n",
      "Epoch 39/50 | Loss: 1.2129 | Acc: 58.47%\n",
      "Epoch 40/50 | Loss: 1.1988 | Acc: 58.94%\n",
      "Epoch 41/50 | Loss: 1.1827 | Acc: 59.70%\n",
      "Epoch 42/50 | Loss: 1.1757 | Acc: 59.83%\n",
      "Epoch 43/50 | Loss: 1.1731 | Acc: 60.21%\n",
      "Epoch 44/50 | Loss: 1.1570 | Acc: 60.65%\n",
      "Epoch 45/50 | Loss: 1.1517 | Acc: 60.97%\n",
      "Epoch 46/50 | Loss: 1.1655 | Acc: 60.55%\n",
      "Epoch 47/50 | Loss: 1.1546 | Acc: 61.10%\n",
      "Epoch 48/50 | Loss: 1.1566 | Acc: 61.04%\n",
      "Epoch 49/50 | Loss: 1.1512 | Acc: 61.09%\n",
      "Epoch 50/50 | Loss: 1.1409 | Acc: 61.36%\n",
      "\n",
      "==== Running Experiment: Optimizer=adam, Scheduler=step ====\n",
      "Epoch 1/50 | Loss: 1.6976 | Acc: 38.56%\n",
      "Epoch 2/50 | Loss: 1.3704 | Acc: 51.40%\n",
      "Epoch 3/50 | Loss: 1.2018 | Acc: 57.96%\n",
      "Epoch 4/50 | Loss: 1.1059 | Acc: 61.45%\n",
      "Epoch 5/50 | Loss: 1.0301 | Acc: 64.48%\n",
      "Epoch 6/50 | Loss: 0.9787 | Acc: 66.31%\n",
      "Epoch 7/50 | Loss: 0.9448 | Acc: 67.47%\n",
      "Epoch 8/50 | Loss: 0.9175 | Acc: 68.53%\n",
      "Epoch 9/50 | Loss: 0.9015 | Acc: 69.17%\n",
      "Epoch 10/50 | Loss: 0.8782 | Acc: 70.04%\n",
      "Epoch 11/50 | Loss: 0.8579 | Acc: 70.88%\n",
      "Epoch 12/50 | Loss: 0.8454 | Acc: 70.93%\n",
      "Epoch 13/50 | Loss: 0.8370 | Acc: 71.48%\n",
      "Epoch 14/50 | Loss: 0.8203 | Acc: 71.90%\n",
      "Epoch 15/50 | Loss: 0.8190 | Acc: 72.07%\n",
      "Epoch 16/50 | Loss: 0.8109 | Acc: 72.38%\n",
      "Epoch 17/50 | Loss: 0.8120 | Acc: 72.41%\n",
      "Epoch 18/50 | Loss: 0.8045 | Acc: 72.52%\n",
      "Epoch 19/50 | Loss: 0.7929 | Acc: 73.06%\n",
      "Epoch 20/50 | Loss: 0.7874 | Acc: 73.23%\n",
      "Epoch 21/50 | Loss: 0.7841 | Acc: 73.36%\n",
      "Epoch 22/50 | Loss: 0.7822 | Acc: 73.51%\n",
      "Epoch 23/50 | Loss: 0.7744 | Acc: 73.65%\n",
      "Epoch 24/50 | Loss: 0.7675 | Acc: 73.70%\n",
      "Epoch 25/50 | Loss: 0.7702 | Acc: 73.88%\n",
      "Epoch 26/50 | Loss: 0.7673 | Acc: 74.22%\n",
      "Epoch 27/50 | Loss: 0.7595 | Acc: 74.16%\n",
      "Epoch 28/50 | Loss: 0.7645 | Acc: 74.18%\n",
      "Epoch 29/50 | Loss: 0.7598 | Acc: 74.29%\n",
      "Epoch 30/50 | Loss: 0.7581 | Acc: 74.13%\n",
      "Epoch 31/50 | Loss: 0.6328 | Acc: 78.53%\n",
      "Epoch 32/50 | Loss: 0.5887 | Acc: 79.99%\n",
      "Epoch 33/50 | Loss: 0.5766 | Acc: 80.30%\n",
      "Epoch 34/50 | Loss: 0.5635 | Acc: 80.81%\n",
      "Epoch 35/50 | Loss: 0.5541 | Acc: 81.18%\n",
      "Epoch 36/50 | Loss: 0.5425 | Acc: 81.61%\n",
      "Epoch 37/50 | Loss: 0.5361 | Acc: 81.84%\n",
      "Epoch 38/50 | Loss: 0.5334 | Acc: 81.80%\n",
      "Epoch 39/50 | Loss: 0.5207 | Acc: 82.31%\n",
      "Epoch 40/50 | Loss: 0.5209 | Acc: 82.39%\n",
      "Epoch 41/50 | Loss: 0.5126 | Acc: 82.46%\n",
      "Epoch 42/50 | Loss: 0.5113 | Acc: 82.36%\n",
      "Epoch 43/50 | Loss: 0.5060 | Acc: 82.69%\n",
      "Epoch 44/50 | Loss: 0.5013 | Acc: 82.95%\n",
      "Epoch 45/50 | Loss: 0.4930 | Acc: 83.15%\n",
      "Epoch 46/50 | Loss: 0.4909 | Acc: 83.27%\n",
      "Epoch 47/50 | Loss: 0.4891 | Acc: 83.30%\n",
      "Epoch 48/50 | Loss: 0.4892 | Acc: 83.35%\n",
      "Epoch 49/50 | Loss: 0.4773 | Acc: 83.62%\n",
      "Epoch 50/50 | Loss: 0.4800 | Acc: 83.49%\n",
      "\n",
      "==== Running Experiment: Optimizer=adam, Scheduler=cosine ====\n",
      "Epoch 1/50 | Loss: 1.6999 | Acc: 38.27%\n",
      "Epoch 2/50 | Loss: 1.3707 | Acc: 51.31%\n",
      "Epoch 3/50 | Loss: 1.2022 | Acc: 58.07%\n",
      "Epoch 4/50 | Loss: 1.0956 | Acc: 61.49%\n",
      "Epoch 5/50 | Loss: 1.0149 | Acc: 64.82%\n",
      "Epoch 6/50 | Loss: 0.9665 | Acc: 66.70%\n",
      "Epoch 7/50 | Loss: 0.9284 | Acc: 67.95%\n",
      "Epoch 8/50 | Loss: 0.8940 | Acc: 69.30%\n",
      "Epoch 9/50 | Loss: 0.8718 | Acc: 69.95%\n",
      "Epoch 10/50 | Loss: 0.8509 | Acc: 70.83%\n",
      "Epoch 11/50 | Loss: 0.8337 | Acc: 71.63%\n",
      "Epoch 12/50 | Loss: 0.8132 | Acc: 72.35%\n",
      "Epoch 13/50 | Loss: 0.8021 | Acc: 72.91%\n",
      "Epoch 14/50 | Loss: 0.7814 | Acc: 73.43%\n",
      "Epoch 15/50 | Loss: 0.7717 | Acc: 73.92%\n",
      "Epoch 16/50 | Loss: 0.7539 | Acc: 74.43%\n",
      "Epoch 17/50 | Loss: 0.7406 | Acc: 74.64%\n",
      "Epoch 18/50 | Loss: 0.7316 | Acc: 75.10%\n",
      "Epoch 19/50 | Loss: 0.7240 | Acc: 75.34%\n",
      "Epoch 20/50 | Loss: 0.7094 | Acc: 76.01%\n",
      "Epoch 21/50 | Loss: 0.6930 | Acc: 76.46%\n",
      "Epoch 22/50 | Loss: 0.6797 | Acc: 76.93%\n",
      "Epoch 23/50 | Loss: 0.6673 | Acc: 77.34%\n",
      "Epoch 24/50 | Loss: 0.6581 | Acc: 77.72%\n",
      "Epoch 25/50 | Loss: 0.6430 | Acc: 78.17%\n",
      "Epoch 26/50 | Loss: 0.6319 | Acc: 78.74%\n",
      "Epoch 27/50 | Loss: 0.6108 | Acc: 79.19%\n",
      "Epoch 28/50 | Loss: 0.6029 | Acc: 79.54%\n",
      "Epoch 29/50 | Loss: 0.5964 | Acc: 79.65%\n",
      "Epoch 30/50 | Loss: 0.5781 | Acc: 80.41%\n",
      "Epoch 31/50 | Loss: 0.5634 | Acc: 80.91%\n",
      "Epoch 32/50 | Loss: 0.5460 | Acc: 81.44%\n",
      "Epoch 33/50 | Loss: 0.5323 | Acc: 81.84%\n",
      "Epoch 34/50 | Loss: 0.5190 | Acc: 82.31%\n",
      "Epoch 35/50 | Loss: 0.5029 | Acc: 82.72%\n",
      "Epoch 36/50 | Loss: 0.4922 | Acc: 83.24%\n",
      "Epoch 37/50 | Loss: 0.4788 | Acc: 83.64%\n",
      "Epoch 38/50 | Loss: 0.4651 | Acc: 83.99%\n",
      "Epoch 39/50 | Loss: 0.4525 | Acc: 84.65%\n",
      "Epoch 40/50 | Loss: 0.4398 | Acc: 85.17%\n",
      "Epoch 41/50 | Loss: 0.4270 | Acc: 85.44%\n",
      "Epoch 42/50 | Loss: 0.4199 | Acc: 85.77%\n",
      "Epoch 43/50 | Loss: 0.4111 | Acc: 86.00%\n",
      "Epoch 44/50 | Loss: 0.3978 | Acc: 86.41%\n",
      "Epoch 45/50 | Loss: 0.3927 | Acc: 86.63%\n",
      "Epoch 46/50 | Loss: 0.3832 | Acc: 86.84%\n",
      "Epoch 47/50 | Loss: 0.3848 | Acc: 86.77%\n",
      "Epoch 48/50 | Loss: 0.3776 | Acc: 87.01%\n",
      "Epoch 49/50 | Loss: 0.3747 | Acc: 87.21%\n",
      "Epoch 50/50 | Loss: 0.3711 | Acc: 87.38%\n",
      "\n",
      "==== Running Experiment: Optimizer=adam, Scheduler=plateau ====\n",
      "Epoch 1/50 | Loss: 1.7150 | Acc: 37.85%\n",
      "Epoch 2/50 | Loss: 1.3893 | Acc: 50.81%\n",
      "Epoch 3/50 | Loss: 1.2271 | Acc: 57.02%\n",
      "Epoch 4/50 | Loss: 1.1104 | Acc: 61.13%\n",
      "Epoch 5/50 | Loss: 1.0326 | Acc: 64.06%\n",
      "Epoch 6/50 | Loss: 0.9813 | Acc: 66.09%\n",
      "Epoch 7/50 | Loss: 0.9461 | Acc: 67.43%\n",
      "Epoch 8/50 | Loss: 0.9160 | Acc: 68.61%\n",
      "Epoch 9/50 | Loss: 0.8952 | Acc: 69.27%\n",
      "Epoch 10/50 | Loss: 0.8719 | Acc: 69.97%\n",
      "Epoch 11/50 | Loss: 0.8562 | Acc: 70.77%\n",
      "Epoch 12/50 | Loss: 0.8523 | Acc: 70.87%\n",
      "Epoch 13/50 | Loss: 0.8328 | Acc: 71.57%\n",
      "Epoch 14/50 | Loss: 0.8321 | Acc: 71.55%\n",
      "Epoch 15/50 | Loss: 0.8191 | Acc: 72.32%\n",
      "Epoch 16/50 | Loss: 0.8111 | Acc: 72.56%\n",
      "Epoch 17/50 | Loss: 0.7991 | Acc: 72.65%\n",
      "Epoch 18/50 | Loss: 0.8036 | Acc: 72.78%\n",
      "Epoch 19/50 | Loss: 0.7950 | Acc: 72.75%\n",
      "Epoch 20/50 | Loss: 0.7897 | Acc: 73.15%\n",
      "Epoch 21/50 | Loss: 0.7860 | Acc: 73.12%\n",
      "Epoch 22/50 | Loss: 0.7836 | Acc: 73.31%\n",
      "Epoch 23/50 | Loss: 0.7730 | Acc: 73.92%\n",
      "Epoch 24/50 | Loss: 0.7730 | Acc: 73.77%\n",
      "Epoch 25/50 | Loss: 0.7705 | Acc: 73.74%\n",
      "Epoch 26/50 | Loss: 0.7691 | Acc: 73.92%\n",
      "Epoch 27/50 | Loss: 0.7634 | Acc: 74.08%\n",
      "Epoch 28/50 | Loss: 0.7571 | Acc: 74.29%\n",
      "Epoch 29/50 | Loss: 0.7626 | Acc: 74.09%\n",
      "Epoch 30/50 | Loss: 0.7607 | Acc: 74.17%\n",
      "Epoch 31/50 | Loss: 0.7466 | Acc: 74.67%\n",
      "Epoch 32/50 | Loss: 0.7511 | Acc: 74.50%\n",
      "Epoch 33/50 | Loss: 0.7530 | Acc: 74.53%\n",
      "Epoch 34/50 | Loss: 0.7501 | Acc: 74.56%\n",
      "Epoch 35/50 | Loss: 0.7492 | Acc: 74.89%\n",
      "Epoch 36/50 | Loss: 0.7494 | Acc: 74.73%\n",
      "Epoch 37/50 | Loss: 0.7405 | Acc: 74.83%\n",
      "Epoch 38/50 | Loss: 0.7391 | Acc: 75.14%\n",
      "Epoch 39/50 | Loss: 0.7388 | Acc: 75.00%\n",
      "Epoch 40/50 | Loss: 0.7368 | Acc: 74.99%\n",
      "Epoch 41/50 | Loss: 0.7385 | Acc: 75.07%\n",
      "Epoch 42/50 | Loss: 0.7285 | Acc: 75.39%\n",
      "Epoch 43/50 | Loss: 0.7326 | Acc: 75.18%\n",
      "Epoch 44/50 | Loss: 0.7323 | Acc: 75.02%\n",
      "Epoch 45/50 | Loss: 0.7286 | Acc: 75.06%\n",
      "Epoch 46/50 | Loss: 0.7287 | Acc: 75.22%\n",
      "Epoch 47/50 | Loss: 0.7266 | Acc: 75.44%\n",
      "Epoch 48/50 | Loss: 0.7244 | Acc: 75.43%\n",
      "Epoch 49/50 | Loss: 0.7265 | Acc: 75.29%\n",
      "Epoch 50/50 | Loss: 0.7220 | Acc: 75.65%\n",
      "\n",
      "==== Running Experiment: Optimizer=rmsprop, Scheduler=step ====\n",
      "Epoch 1/50 | Loss: 1.9881 | Acc: 26.74%\n",
      "Epoch 2/50 | Loss: 1.7428 | Acc: 35.18%\n",
      "Epoch 3/50 | Loss: 1.7016 | Acc: 37.21%\n",
      "Epoch 4/50 | Loss: 1.6743 | Acc: 38.44%\n",
      "Epoch 5/50 | Loss: 1.6648 | Acc: 38.90%\n",
      "Epoch 6/50 | Loss: 1.6572 | Acc: 39.40%\n",
      "Epoch 7/50 | Loss: 1.6596 | Acc: 39.35%\n",
      "Epoch 8/50 | Loss: 1.6531 | Acc: 39.47%\n",
      "Epoch 9/50 | Loss: 1.6446 | Acc: 39.61%\n",
      "Epoch 10/50 | Loss: 1.6519 | Acc: 39.34%\n",
      "Epoch 11/50 | Loss: 1.6430 | Acc: 39.60%\n",
      "Epoch 12/50 | Loss: 1.6425 | Acc: 39.90%\n",
      "Epoch 13/50 | Loss: 1.6399 | Acc: 39.66%\n",
      "Epoch 14/50 | Loss: 1.6249 | Acc: 41.06%\n",
      "Epoch 15/50 | Loss: 1.6254 | Acc: 40.64%\n",
      "Epoch 16/50 | Loss: 1.6221 | Acc: 40.54%\n",
      "Epoch 17/50 | Loss: 1.6090 | Acc: 41.20%\n",
      "Epoch 18/50 | Loss: 1.6144 | Acc: 41.34%\n",
      "Epoch 19/50 | Loss: 1.6113 | Acc: 41.40%\n",
      "Epoch 20/50 | Loss: 1.6100 | Acc: 41.42%\n",
      "Epoch 21/50 | Loss: 1.6068 | Acc: 41.67%\n",
      "Epoch 22/50 | Loss: 1.5949 | Acc: 42.16%\n",
      "Epoch 23/50 | Loss: 1.5950 | Acc: 42.32%\n",
      "Epoch 24/50 | Loss: 1.5818 | Acc: 42.75%\n",
      "Epoch 25/50 | Loss: 1.5914 | Acc: 42.36%\n",
      "Epoch 26/50 | Loss: 1.5884 | Acc: 42.56%\n",
      "Epoch 27/50 | Loss: 1.5921 | Acc: 42.38%\n",
      "Epoch 28/50 | Loss: 1.5888 | Acc: 42.38%\n",
      "Epoch 29/50 | Loss: 1.5872 | Acc: 42.56%\n",
      "Epoch 30/50 | Loss: 1.5836 | Acc: 42.80%\n",
      "Epoch 31/50 | Loss: 1.3839 | Acc: 50.51%\n",
      "Epoch 32/50 | Loss: 1.3193 | Acc: 52.83%\n",
      "Epoch 33/50 | Loss: 1.2632 | Acc: 55.09%\n",
      "Epoch 34/50 | Loss: 1.2172 | Acc: 56.83%\n",
      "Epoch 35/50 | Loss: 1.1868 | Acc: 58.19%\n",
      "Epoch 36/50 | Loss: 1.1512 | Acc: 59.48%\n",
      "Epoch 37/50 | Loss: 1.1240 | Acc: 60.22%\n",
      "Epoch 38/50 | Loss: 1.1019 | Acc: 61.23%\n",
      "Epoch 39/50 | Loss: 1.0800 | Acc: 62.23%\n",
      "Epoch 40/50 | Loss: 1.0663 | Acc: 62.62%\n",
      "Epoch 41/50 | Loss: 1.0454 | Acc: 63.54%\n",
      "Epoch 42/50 | Loss: 1.0364 | Acc: 63.75%\n",
      "Epoch 43/50 | Loss: 1.0229 | Acc: 64.17%\n",
      "Epoch 44/50 | Loss: 1.0183 | Acc: 64.65%\n",
      "Epoch 45/50 | Loss: 1.0107 | Acc: 64.91%\n",
      "Epoch 46/50 | Loss: 1.0018 | Acc: 64.93%\n",
      "Epoch 47/50 | Loss: 0.9985 | Acc: 65.28%\n",
      "Epoch 48/50 | Loss: 0.9876 | Acc: 65.52%\n",
      "Epoch 49/50 | Loss: 0.9824 | Acc: 65.61%\n",
      "Epoch 50/50 | Loss: 0.9716 | Acc: 65.97%\n",
      "\n",
      "==== Running Experiment: Optimizer=rmsprop, Scheduler=cosine ====\n",
      "Epoch 1/50 | Loss: 1.9938 | Acc: 26.77%\n",
      "Epoch 2/50 | Loss: 1.7548 | Acc: 34.85%\n",
      "Epoch 3/50 | Loss: 1.7062 | Acc: 36.72%\n",
      "Epoch 4/50 | Loss: 1.6862 | Acc: 37.88%\n",
      "Epoch 5/50 | Loss: 1.6835 | Acc: 37.89%\n",
      "Epoch 6/50 | Loss: 1.6663 | Acc: 38.47%\n",
      "Epoch 7/50 | Loss: 1.6669 | Acc: 38.82%\n",
      "Epoch 8/50 | Loss: 1.6568 | Acc: 39.39%\n",
      "Epoch 9/50 | Loss: 1.6384 | Acc: 39.88%\n",
      "Epoch 10/50 | Loss: 1.6329 | Acc: 40.00%\n",
      "Epoch 11/50 | Loss: 1.6129 | Acc: 40.83%\n",
      "Epoch 12/50 | Loss: 1.5978 | Acc: 41.50%\n",
      "Epoch 13/50 | Loss: 1.5906 | Acc: 41.71%\n",
      "Epoch 14/50 | Loss: 1.5790 | Acc: 42.49%\n",
      "Epoch 15/50 | Loss: 1.5664 | Acc: 43.23%\n",
      "Epoch 16/50 | Loss: 1.5558 | Acc: 43.17%\n",
      "Epoch 17/50 | Loss: 1.5527 | Acc: 43.41%\n",
      "Epoch 18/50 | Loss: 1.5434 | Acc: 44.12%\n",
      "Epoch 19/50 | Loss: 1.5353 | Acc: 44.05%\n",
      "Epoch 20/50 | Loss: 1.5148 | Acc: 44.93%\n",
      "Epoch 21/50 | Loss: 1.5107 | Acc: 45.12%\n",
      "Epoch 22/50 | Loss: 1.4926 | Acc: 45.90%\n",
      "Epoch 23/50 | Loss: 1.4835 | Acc: 46.39%\n",
      "Epoch 24/50 | Loss: 1.4694 | Acc: 47.11%\n",
      "Epoch 25/50 | Loss: 1.4518 | Acc: 47.78%\n",
      "Epoch 26/50 | Loss: 1.4365 | Acc: 48.06%\n",
      "Epoch 27/50 | Loss: 1.4186 | Acc: 48.99%\n",
      "Epoch 28/50 | Loss: 1.4089 | Acc: 49.51%\n",
      "Epoch 29/50 | Loss: 1.3900 | Acc: 50.39%\n",
      "Epoch 30/50 | Loss: 1.3701 | Acc: 50.81%\n",
      "Epoch 31/50 | Loss: 1.3669 | Acc: 51.12%\n",
      "Epoch 32/50 | Loss: 1.3522 | Acc: 51.82%\n",
      "Epoch 33/50 | Loss: 1.3290 | Acc: 52.47%\n",
      "Epoch 34/50 | Loss: 1.3232 | Acc: 52.80%\n",
      "Epoch 35/50 | Loss: 1.3032 | Acc: 53.54%\n",
      "Epoch 36/50 | Loss: 1.2882 | Acc: 54.19%\n",
      "Epoch 37/50 | Loss: 1.2671 | Acc: 54.88%\n",
      "Epoch 38/50 | Loss: 1.2529 | Acc: 55.26%\n",
      "Epoch 39/50 | Loss: 1.2388 | Acc: 55.80%\n",
      "Epoch 40/50 | Loss: 1.2235 | Acc: 56.21%\n",
      "Epoch 41/50 | Loss: 1.2098 | Acc: 56.95%\n",
      "Epoch 42/50 | Loss: 1.1927 | Acc: 57.52%\n",
      "Epoch 43/50 | Loss: 1.1768 | Acc: 58.03%\n",
      "Epoch 44/50 | Loss: 1.1551 | Acc: 59.15%\n",
      "Epoch 45/50 | Loss: 1.1421 | Acc: 59.63%\n",
      "Epoch 46/50 | Loss: 1.1303 | Acc: 60.05%\n",
      "Epoch 47/50 | Loss: 1.1106 | Acc: 60.78%\n",
      "Epoch 48/50 | Loss: 1.0971 | Acc: 61.26%\n",
      "Epoch 49/50 | Loss: 1.0869 | Acc: 61.71%\n",
      "Epoch 50/50 | Loss: 1.0803 | Acc: 61.88%\n",
      "\n",
      "==== Running Experiment: Optimizer=rmsprop, Scheduler=plateau ====\n",
      "Epoch 1/50 | Loss: 2.0108 | Acc: 26.23%\n",
      "Epoch 2/50 | Loss: 1.7511 | Acc: 35.26%\n",
      "Epoch 3/50 | Loss: 1.7141 | Acc: 37.16%\n",
      "Epoch 4/50 | Loss: 1.6815 | Acc: 38.22%\n",
      "Epoch 5/50 | Loss: 1.6621 | Acc: 38.86%\n",
      "Epoch 6/50 | Loss: 1.6454 | Acc: 39.94%\n",
      "Epoch 7/50 | Loss: 1.6483 | Acc: 39.78%\n",
      "Epoch 8/50 | Loss: 1.6424 | Acc: 40.00%\n",
      "Epoch 9/50 | Loss: 1.6334 | Acc: 40.18%\n",
      "Epoch 10/50 | Loss: 1.6362 | Acc: 40.25%\n",
      "Epoch 11/50 | Loss: 1.6300 | Acc: 40.70%\n",
      "Epoch 12/50 | Loss: 1.6246 | Acc: 40.82%\n",
      "Epoch 13/50 | Loss: 1.6216 | Acc: 41.20%\n",
      "Epoch 14/50 | Loss: 1.6060 | Acc: 41.14%\n",
      "Epoch 15/50 | Loss: 1.6084 | Acc: 41.34%\n",
      "Epoch 16/50 | Loss: 1.6086 | Acc: 41.31%\n",
      "Epoch 17/50 | Loss: 1.6088 | Acc: 41.32%\n",
      "Epoch 18/50 | Loss: 1.5973 | Acc: 41.73%\n",
      "Epoch 19/50 | Loss: 1.6117 | Acc: 41.35%\n",
      "Epoch 20/50 | Loss: 1.6108 | Acc: 41.12%\n",
      "Epoch 21/50 | Loss: 1.5997 | Acc: 41.53%\n",
      "Epoch 22/50 | Loss: 1.5986 | Acc: 41.49%\n",
      "Epoch 23/50 | Loss: 1.6023 | Acc: 41.56%\n",
      "Epoch 24/50 | Loss: 1.6010 | Acc: 41.52%\n",
      "Epoch 25/50 | Loss: 1.4874 | Acc: 45.66%\n",
      "Epoch 26/50 | Loss: 1.4714 | Acc: 46.47%\n",
      "Epoch 27/50 | Loss: 1.4646 | Acc: 46.90%\n",
      "Epoch 28/50 | Loss: 1.4578 | Acc: 47.29%\n",
      "Epoch 29/50 | Loss: 1.4460 | Acc: 47.64%\n",
      "Epoch 30/50 | Loss: 1.4351 | Acc: 48.52%\n",
      "Epoch 31/50 | Loss: 1.4309 | Acc: 48.46%\n",
      "Epoch 32/50 | Loss: 1.4230 | Acc: 48.63%\n",
      "Epoch 33/50 | Loss: 1.4266 | Acc: 48.84%\n",
      "Epoch 34/50 | Loss: 1.4214 | Acc: 49.30%\n",
      "Epoch 35/50 | Loss: 1.4255 | Acc: 48.54%\n",
      "Epoch 36/50 | Loss: 1.4175 | Acc: 49.21%\n",
      "Epoch 37/50 | Loss: 1.4151 | Acc: 49.23%\n",
      "Epoch 38/50 | Loss: 1.4087 | Acc: 49.39%\n",
      "Epoch 39/50 | Loss: 1.4171 | Acc: 49.20%\n",
      "Epoch 40/50 | Loss: 1.4083 | Acc: 49.56%\n",
      "Epoch 41/50 | Loss: 1.4014 | Acc: 49.45%\n",
      "Epoch 42/50 | Loss: 1.4088 | Acc: 49.54%\n",
      "Epoch 43/50 | Loss: 1.4045 | Acc: 49.51%\n",
      "Epoch 44/50 | Loss: 1.4043 | Acc: 49.69%\n",
      "Epoch 45/50 | Loss: 1.4101 | Acc: 49.53%\n",
      "Epoch 46/50 | Loss: 1.3930 | Acc: 50.08%\n",
      "Epoch 47/50 | Loss: 1.3994 | Acc: 49.80%\n",
      "Epoch 48/50 | Loss: 1.3998 | Acc: 49.90%\n",
      "Epoch 49/50 | Loss: 1.4027 | Acc: 50.05%\n",
      "Epoch 50/50 | Loss: 1.4015 | Acc: 49.51%\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('sgd', 'step', 68.62, 71.53),\n ('sgd', 'cosine', 83.464, 82.89),\n ('sgd', 'plateau', 61.36, 65.79),\n ('adam', 'step', 83.492, 83.53),\n ('adam', 'cosine', 87.382, 84.69),\n ('adam', 'plateau', 75.646, 77.82),\n ('rmsprop', 'step', 65.968, 69.29),\n ('rmsprop', 'cosine', 61.88, 65.91),\n ('rmsprop', 'plateau', 49.512, 56.01)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN训练调优实验扩展实现：CIFAR-10，ResNet-18，自定义CNN，优化器与学习率策略对比\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# 设置超参数\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# CIFAR-10 数据增强与加载\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# 自定义CNN结构\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8*8*128, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 所有实验组合\n",
    "optimizers = ['sgd', 'adam', 'rmsprop']\n",
    "schedulers = ['step', 'cosine', 'plateau']\n",
    "\n",
    "# 实验主函数\n",
    "def run_experiments(model_name='custom', log_dir='logs'):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    results = []\n",
    "    for opt_name in optimizers:\n",
    "        for sch_name in schedulers:\n",
    "            print(f\"\\n==== Running Experiment: Optimizer={opt_name}, Scheduler={sch_name} ====\")\n",
    "\n",
    "            # 初始化模型\n",
    "            if model_name == 'resnet':\n",
    "                model = resnet18(num_classes=10,  pretrained=False)\n",
    "            else:\n",
    "                model = CustomCNN()\n",
    "            model = model.to(device)\n",
    "\n",
    "            # 定义优化器\n",
    "            if opt_name == 'sgd':\n",
    "                optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "            elif opt_name == 'adam':\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "            elif opt_name == 'rmsprop':\n",
    "                optimizer = optim.RMSprop(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "            # 定义调度器\n",
    "            if sch_name == 'step':\n",
    "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "            elif sch_name == 'cosine':\n",
    "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            elif sch_name == 'plateau':\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            train_losses, train_accs = [], []\n",
    "\n",
    "            # 开始训练\n",
    "            start_train_time = time.time()\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                running_loss, correct, total = 0.0, 0, 0\n",
    "                for inputs, targets in trainloader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * targets.size(0)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                acc = 100. * correct / total\n",
    "                loss = running_loss / total\n",
    "                train_losses.append(loss)\n",
    "                train_accs.append(acc)\n",
    "                print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss:.4f} | Acc: {acc:.2f}%\")\n",
    "\n",
    "                if sch_name == 'plateau':\n",
    "                    scheduler.step(loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            train_time = time.time() - start_train_time\n",
    "\n",
    "            # 测试\n",
    "            model.eval()\n",
    "            correct, total = 0, 0\n",
    "            start_test_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in testloader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += predicted.eq(targets).sum().item()\n",
    "            test_time = time.time() - start_test_time\n",
    "            test_acc = 100. * correct / total\n",
    "\n",
    "            # FLOPs & 参数\n",
    "            with torch.cuda.device(0):\n",
    "                macs, params = get_model_complexity_info(model, (3, 32, 32), as_strings=False, print_per_layer_stat=False)\n",
    "            model_size = os.path.getsize(torch.save(model.state_dict(), os.path.join(log_dir, f\"temp_{opt_name}_{sch_name}.pth\")) or os.path.join(log_dir, f\"temp_{opt_name}_{sch_name}.pth\")) / 1024 / 1024\n",
    "\n",
    "            # 保存日志\n",
    "            log_path = os.path.join(log_dir, f\"log_{opt_name}_{sch_name}.txt\")\n",
    "            with open(log_path, 'w') as f:\n",
    "                f.write(f\"Optimizer: {opt_name}\\n\")\n",
    "                f.write(f\"Scheduler: {sch_name}\\n\")\n",
    "                f.write(f\"Final Train Acc: {train_accs[-1]:.2f}%\\n\")\n",
    "                f.write(f\"Test Acc: {test_acc:.2f}%\\n\")\n",
    "                f.write(f\"Train Time: {train_time:.2f}s\\n\")\n",
    "                f.write(f\"Test Time: {test_time:.2f}s\\n\")\n",
    "                f.write(f\"FLOPs: {macs / 1e6:.2f} MFLOPs\\n\")\n",
    "                f.write(f\"Params: {params / 1e6:.2f} M\\n\")\n",
    "                f.write(f\"Model Size: {model_size:.2f} MB\\n\")\n",
    "\n",
    "            # 绘图\n",
    "            plt.figure()\n",
    "            plt.plot(range(1, epochs+1), train_losses, label='Loss')\n",
    "            plt.plot(range(1, epochs+1), train_accs, label='Accuracy')\n",
    "            plt.title(f\"{opt_name.upper()} + {sch_name}\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(log_dir, f\"curve_{opt_name}_{sch_name}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            results.append((opt_name, sch_name, train_accs[-1], test_acc))\n",
    "\n",
    "    return results\n",
    "\n",
    "# 执行所有实验\n",
    "run_experiments(model_name='resnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T13:55:40.320663600Z",
     "start_time": "2025-05-26T07:56:20.920250700Z"
    }
   },
   "id": "7ca683b72c5cfa70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b972d7ea321670a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
